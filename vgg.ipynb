{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VGG MODEL"
      ],
      "metadata": {
        "id": "4i0bktXXsxdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FffX1II8XGF0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torchvision import transforms , datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# The following is to downlaod and use pretrained models from the model-zoo\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "trans = transforms.Compose([transforms.RandomCrop(32, 4), transforms.ToTensor(),normalize])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=trans)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=trans)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=2*batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ5KFWQphZNn",
        "outputId": "6553ce4c-6d12-4ceb-e31b-e19adb3cb18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRCXGPzaZ5xf",
        "outputId": "6ce35691-f810-412b-9e2b-1b4ae99a284b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg19_bn.parameters(), lr=0.001)\n",
        "# input_lastLayer = vgg19_bn.classifier[1].in_features\n",
        "# vgg19_bn.classifier[1] = nn.Linear(input_lastLayer,10)\n",
        "# vgg19_bn = vgg19_bn.to(device)"
      ],
      "metadata": {
        "id": "Ma8LXiPcXrs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG11 with Group Normalisation\n",
        "creating custom vgg models as pretrained models couldnot be loaded due to pytorch cuda out of memory error."
      ],
      "metadata": {
        "id": "kscFeG8bDAtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled7.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1wO-BWgR8eCOKwaw2IIG5CJ35JHpBkVyg\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# from vgg import vgg11_bn\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torchvision import transforms , datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# The following is to downlaod and use pretrained models from the model-zoo\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "'''\n",
        "Modified from https://github.com/pytorch/vision.git\n",
        "'''\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "__all__ = [\n",
        "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    '''\n",
        "    VGG model\n",
        "    '''\n",
        "    def __init__(self, features):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "         # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.GroupNorm(32,v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M',\n",
        "          512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "def vgg11():\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
        "    return VGG(make_layers(cfg['A']))\n",
        "\n",
        "\n",
        "def vgg11_bn():\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
        "    return VGG(make_layers(cfg['A'], batch_norm=True))\n",
        "\n",
        "\n",
        "def vgg13():\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\")\"\"\"\n",
        "    return VGG(make_layers(cfg['B']))\n",
        "\n",
        "\n",
        "def vgg13_bn():\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
        "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
        "\n",
        "\n",
        "def vgg16():\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\")\"\"\"\n",
        "    return VGG(make_layers(cfg['D']))\n",
        "\n",
        "\n",
        "def vgg16_bn():\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n",
        "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
        "\n",
        "\n",
        "def vgg19():\n",
        "    \"\"\"VGG 19-layer model (configuration \"E\")\"\"\"\n",
        "    return VGG(make_layers(cfg['E']))\n",
        "\n",
        "\n",
        "def vgg19_bn():\n",
        "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
        "    return VGG(make_layers(cfg['E'], batch_norm=True))\n",
        "\n",
        "model=vgg11_bn()"
      ],
      "metadata": {
        "id": "H8gzooNqg3CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNx6uDtZhseK",
        "outputId": "602ff875-3656-4a91-e106-b1b1ff459a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "# # Freeze the layers\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))\n",
        "print(model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), 0.001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#TRAINING THE NETWORK using GN\n",
        "from tqdm import tqdm\n",
        "model = model.to(device)\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(trainloader)\n",
        "    i = 0\n",
        "    for data in pbar:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        pbar.set_description(\"Processing epoch {:d} minibatch {:d} train loss {:.3f}\".format(epoch,\\\n",
        "                                                            i+1, running_loss/(i+1)))\n",
        "        i += 1\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntm6NK43hj5_",
        "outputId": "b9503ca7-2ffd-458d-e01c-ead091f8e70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "         GroupNorm-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
            "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
            "         GroupNorm-6          [-1, 128, 16, 16]             256\n",
            "              ReLU-7          [-1, 128, 16, 16]               0\n",
            "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
            "        GroupNorm-10            [-1, 256, 8, 8]             512\n",
            "             ReLU-11            [-1, 256, 8, 8]               0\n",
            "           Conv2d-12            [-1, 256, 8, 8]         590,080\n",
            "        GroupNorm-13            [-1, 256, 8, 8]             512\n",
            "             ReLU-14            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-15            [-1, 256, 4, 4]               0\n",
            "           Conv2d-16            [-1, 512, 4, 4]       1,180,160\n",
            "        GroupNorm-17            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-18            [-1, 512, 4, 4]               0\n",
            "           Conv2d-19            [-1, 512, 4, 4]       2,359,808\n",
            "        GroupNorm-20            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-21            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-22            [-1, 512, 2, 2]               0\n",
            "           Conv2d-23            [-1, 512, 2, 2]       2,359,808\n",
            "        GroupNorm-24            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-25            [-1, 512, 2, 2]               0\n",
            "           Conv2d-26            [-1, 512, 2, 2]       2,359,808\n",
            "        GroupNorm-27            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-28            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-29            [-1, 512, 1, 1]               0\n",
            "          Dropout-30                  [-1, 512]               0\n",
            "           Linear-31                  [-1, 512]         262,656\n",
            "             ReLU-32                  [-1, 512]               0\n",
            "          Dropout-33                  [-1, 512]               0\n",
            "           Linear-34                  [-1, 512]         262,656\n",
            "             ReLU-35                  [-1, 512]               0\n",
            "           Linear-36                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 9,756,426\n",
            "Trainable params: 9,756,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.73\n",
            "Params size (MB): 37.22\n",
            "Estimated Total Size (MB): 40.96\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 0 minibatch 196 train loss 2.318: 100%|██████████| 196/196 [00:22<00:00,  8.58it/s]\n",
            "Processing epoch 1 minibatch 196 train loss 2.310: 100%|██████████| 196/196 [00:22<00:00,  8.54it/s]\n",
            "Processing epoch 2 minibatch 196 train loss 2.305: 100%|██████████| 196/196 [00:20<00:00,  9.69it/s]\n",
            "Processing epoch 3 minibatch 196 train loss 2.301: 100%|██████████| 196/196 [00:21<00:00,  9.10it/s]\n",
            "Processing epoch 4 minibatch 196 train loss 2.298: 100%|██████████| 196/196 [00:21<00:00,  9.28it/s]\n",
            "Processing epoch 5 minibatch 196 train loss 2.293: 100%|██████████| 196/196 [00:20<00:00,  9.74it/s]\n",
            "Processing epoch 6 minibatch 196 train loss 2.287: 100%|██████████| 196/196 [00:21<00:00,  9.00it/s]\n",
            "Processing epoch 7 minibatch 196 train loss 2.280: 100%|██████████| 196/196 [00:20<00:00,  9.73it/s]\n",
            "Processing epoch 8 minibatch 196 train loss 2.270: 100%|██████████| 196/196 [00:20<00:00,  9.39it/s]\n",
            "Processing epoch 9 minibatch 196 train loss 2.255: 100%|██████████| 196/196 [00:20<00:00,  9.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing model accuracy on normal images"
      ],
      "metadata": {
        "id": "27retdoJDmyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(testloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h3O-7CThnjt",
        "outputId": "08a7d5bd-8a7c-4235-e3e6-f378bf690e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 20 test accuracy 22.77%: 100%|██████████| 20/20 [00:03<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 22.77 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading corrupted images from drive"
      ],
      "metadata": {
        "id": "UntpCvNSDutJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "path = '/content/drive/MyDrive/CV_final_project_files/'\n",
        "filenames = [filename for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
        "filenames.sort()\n",
        "\n",
        "images = []\n",
        "for filename in filenames:\n",
        "    img = Image.open(os.path.join(path, filename))\n",
        "\n",
        "    images.append(trans(img))\n",
        "\n",
        "labels=[]\n",
        "for tensor in testloader:\n",
        "  for label in tensor[1]:\n",
        "    labels.append(label.item())\n",
        "\n",
        "currtestset = torch.utils.data.TensorDataset(torch.stack(images), torch.tensor(labels))\n",
        "currtestloader = torch.utils.data.DataLoader(currtestset, batch_size=2*batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "LFiltvjWheYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing model accuracy on corrupted images"
      ],
      "metadata": {
        "id": "d9p2JcpaD9zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(currtestloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))"
      ],
      "metadata": {
        "id": "WXi1N1ynhbev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64b85a4-4bba-46e1-c57f-aa5b7e9fdc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 47 test accuracy 20.99%: 100%|██████████| 47/47 [00:07<00:00,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 20.99 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG11 with Batch Normalisation"
      ],
      "metadata": {
        "id": "IbVnazheEX29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled7.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1wO-BWgR8eCOKwaw2IIG5CJ35JHpBkVyg\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# from vgg import vgg11_bn\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torchvision import transforms , datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# The following is to downlaod and use pretrained models from the model-zoo\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "'''\n",
        "Modified from https://github.com/pytorch/vision.git\n",
        "'''\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "__all__ = [\n",
        "    'VGG_bn', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]\n",
        "\n",
        "\n",
        "class VGG_bn(nn.Module):\n",
        "    '''\n",
        "    VGG model\n",
        "    '''\n",
        "    def __init__(self, features):\n",
        "        super(VGG_bn, self).__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "         # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M',\n",
        "          512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "def vgg11():\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['A']))\n",
        "\n",
        "\n",
        "def vgg11_bn():\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['A'], batch_norm=True))\n",
        "\n",
        "\n",
        "def vgg13():\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\")\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['B']))\n",
        "\n",
        "\n",
        "def vgg13_bn():\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
        "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
        "\n",
        "\n",
        "def vgg16():\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\")\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['D']))\n",
        "\n",
        "\n",
        "def vgg16_bn():\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['D'], batch_norm=True))\n",
        "\n",
        "\n",
        "def vgg19():\n",
        "    \"\"\"VGG 19-layer model (configuration \"E\")\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['E']))\n",
        "\n",
        "\n",
        "def vgg19_bn():\n",
        "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
        "    return VGG_bn(make_layers(cfg['E'], batch_norm=True))\n"
      ],
      "metadata": {
        "id": "6FPspJJ9Ef0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bn=vgg11_bn()"
      ],
      "metadata": {
        "id": "75DFQ8cVOdZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2TVtaz-FeM-",
        "outputId": "2a7e3ac3-d2cd-48d4-f7c7-2f577927dc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG_bn(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model_bn.cuda()\n",
        "# # Freeze the layers\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model_bn, (3, 32, 32))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), 0.001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#TRAINING THE NETWORK using GN\n",
        "from tqdm import tqdm\n",
        "model_bn = model_bn.to(device)\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(trainloader)\n",
        "    i = 0\n",
        "    for data in pbar:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model_bn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        pbar.set_description(\"Processing epoch {:d} minibatch {:d} train loss {:.3f}\".format(epoch,\\\n",
        "                                                            i+1, running_loss/(i+1)))\n",
        "        i += 1\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Yn4ievGCrn",
        "outputId": "d77e5a3a-63e2-4c3e-fc4b-0628a6161fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
            "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
            "              ReLU-7          [-1, 128, 16, 16]               0\n",
            "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-10            [-1, 256, 8, 8]             512\n",
            "             ReLU-11            [-1, 256, 8, 8]               0\n",
            "           Conv2d-12            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-13            [-1, 256, 8, 8]             512\n",
            "             ReLU-14            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-15            [-1, 256, 4, 4]               0\n",
            "           Conv2d-16            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-17            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-18            [-1, 512, 4, 4]               0\n",
            "           Conv2d-19            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-20            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-21            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-22            [-1, 512, 2, 2]               0\n",
            "           Conv2d-23            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-24            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-25            [-1, 512, 2, 2]               0\n",
            "           Conv2d-26            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-27            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-28            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-29            [-1, 512, 1, 1]               0\n",
            "          Dropout-30                  [-1, 512]               0\n",
            "           Linear-31                  [-1, 512]         262,656\n",
            "             ReLU-32                  [-1, 512]               0\n",
            "          Dropout-33                  [-1, 512]               0\n",
            "           Linear-34                  [-1, 512]         262,656\n",
            "             ReLU-35                  [-1, 512]               0\n",
            "           Linear-36                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 9,756,426\n",
            "Trainable params: 9,756,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.73\n",
            "Params size (MB): 37.22\n",
            "Estimated Total Size (MB): 40.96\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 0 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:38<00:00, 40.33it/s]\n",
            "Processing epoch 1 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:37<00:00, 41.92it/s]\n",
            "Processing epoch 2 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:37<00:00, 41.52it/s]\n",
            "Processing epoch 3 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:37<00:00, 41.46it/s]\n",
            "Processing epoch 4 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:37<00:00, 41.16it/s]\n",
            "Processing epoch 5 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:36<00:00, 42.27it/s]\n",
            "Processing epoch 6 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:38<00:00, 40.59it/s]\n",
            "Processing epoch 7 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:37<00:00, 41.14it/s]\n",
            "Processing epoch 8 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:37<00:00, 41.92it/s]\n",
            "Processing epoch 9 minibatch 1563 train loss 2.312: 100%|██████████| 1563/1563 [00:38<00:00, 40.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "model_bn.eval()\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(testloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_bn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-L1zFxGPKM",
        "outputId": "4cc0e633-6bff-41fa-dae3-1877cb48526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 157 test accuracy 10.22%: 100%|██████████| 157/157 [00:08<00:00, 18.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 10.22 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(currtestloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_bn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTvWKgjNGhqc",
        "outputId": "735fa6d2-f34f-4e47-e2a0-5bb6d901e555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 47 test accuracy 9.59%: 100%|██████████| 47/47 [00:00<00:00, 75.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 9.59 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#         Finished\n",
        "\n"
      ],
      "metadata": {
        "id": "J_XVJD0qKbGL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hOxnAZTlTaxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}