{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torchvision import transforms , datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UNgHw3NEmh3u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CIFAR10 using ResNEt50 with Batch Normalization layer"
      ],
      "metadata": {
        "id": "sw4DM3hEkUSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "HRqh5osHgoU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ac0fdb-d66a-4e4f-ce25-ab5459b5a108"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet50 model\n",
        "resnet50_bn= models.resnet50(pretrained=True)\n"
      ],
      "metadata": {
        "id": "TcMGdHwKbikS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e432b3db-1643-45f6-b9dd-8f90e2a9c529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#put model weights on gpu\n",
        "if torch.cuda.is_available():\n",
        "    resnet50_bn.cuda()"
      ],
      "metadata": {
        "id": "T9AG43IEbxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "batch_size=256\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "trans = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(),normalize])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=trans)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=trans)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=2*batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBHiaN_5djrv",
        "outputId": "c8860067-7a88-4b82-aec0-2d2951e665c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:15<00:00, 11101403.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers\n",
        "for param in resnet50_bn.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "DBSxQ76TeLQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add classifier layer for 10 class as pretrained model is trained on imagenet which classifies 1000 classes\n",
        "resnet50_bn.fc = nn.Sequential(\n",
        "                      nn.Linear(2048, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(256, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "IE2iso-beb0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet50_ln.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "9RxdCRmqefLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING THE NETWORK\n",
        "from tqdm import tqdm\n",
        "resnet50 = resnet50_bn.to(device)\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(trainloader)\n",
        "    i = 0\n",
        "    for data in pbar:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        pbar.set_description(\"Processing epoch {:d} minibatch {:d} train loss {:.3f}\".format(epoch,\\\n",
        "                                                            i+1, running_loss/(i+1)))\n",
        "        i += 1\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9_xEuWVeoh3",
        "outputId": "d53b9215-8ed9-4d7b-ee5a-b983fddd4af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 0 minibatch 196 train loss 0.781: 100%|██████████| 196/196 [03:03<00:00,  1.07it/s]\n",
            "Processing epoch 1 minibatch 196 train loss 0.574: 100%|██████████| 196/196 [02:59<00:00,  1.09it/s]\n",
            "Processing epoch 2 minibatch 196 train loss 0.535: 100%|██████████| 196/196 [02:58<00:00,  1.10it/s]\n",
            "Processing epoch 3 minibatch 196 train loss 0.519: 100%|██████████| 196/196 [02:58<00:00,  1.10it/s]\n",
            "Processing epoch 4 minibatch 196 train loss 0.508: 100%|██████████| 196/196 [03:05<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet50,'/content/drive/MyDrive/CV_final_project_files/resnet50_bn.pt')"
      ],
      "metadata": {
        "id": "HhEGgdA4fzib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on Normal Images"
      ],
      "metadata": {
        "id": "lmv9J3VUr4G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(testloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = resnet50(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-6HQRjLf8UM",
        "outputId": "6096e6be-4155-44da-d495-390fd3624472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 20 test accuracy 81.87%: 100%|██████████| 20/20 [00:38<00:00,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 81.87 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ct42M9_UlF3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code to create corrupted images"
      ],
      "metadata": {
        "id": "INl1K3KUlGd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imagecorruptions import corrupt\n",
        "from imagecorruptions import get_corruption_names\n",
        "test_curr=np.empty((10000,32,32,3))\n",
        "for i,image in enumerate(X_test):\n",
        "    corruption_name = np.random.choice(curr_names)\n",
        "    corrupted = corrupt(image, corruption_name=corruption_name, severity=1)\n",
        "    test_curr[i]=corrupted\n",
        "test_curr=test_curr.astype(int)\n",
        "curr_names=get_corruption_names()"
      ],
      "metadata": {
        "id": "s05FP2lItlFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_names"
      ],
      "metadata": {
        "id": "d3_o9gIWH2X7",
        "outputId": "7d9a66e0-df3d-4a3d-cea4-624626ef2be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gaussian_noise',\n",
              " 'shot_noise',\n",
              " 'impulse_noise',\n",
              " 'defocus_blur',\n",
              " 'glass_blur',\n",
              " 'motion_blur',\n",
              " 'zoom_blur',\n",
              " 'snow',\n",
              " 'frost',\n",
              " 'fog',\n",
              " 'brightness',\n",
              " 'contrast',\n",
              " 'elastic_transform',\n",
              " 'pixelate',\n",
              " 'jpeg_compression']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_names.remove('glass_blur')"
      ],
      "metadata": {
        "id": "OZJUzIT_lYjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save corrupted image in Google drive"
      ],
      "metadata": {
        "id": "9YgFyoZnlkxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = \"/content/drive/MyDrive/CV_final_project_files/\"\n",
        "\n",
        "# Save the images with automatically generated file names\n",
        "for i, image in enumerate(test_curr):\n",
        "    # Generate a file name using a pattern or index\n",
        "    file_name = os.path.join(output_directory, f\"curr_image_{i:04d}.jpg\")\n",
        "\n",
        "    # Convert the NumPy array to a Pillow image\n",
        "    pil_image = Image.fromarray(np.uint8(image))\n",
        "\n",
        "    # Save the image to the specified file\n",
        "    pil_image.save(file_name)"
      ],
      "metadata": {
        "id": "xTL7w-b0iDy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to load the corrupt images in dataloader"
      ],
      "metadata": {
        "id": "nSfciQI5r-0i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "path = '/content/drive/MyDrive/CV_final_project_files/'\n",
        "filenames = [filename for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
        "filenames.sort()\n",
        "\n",
        "images = []\n",
        "for filename in filenames[0:2000]:\n",
        "    img = Image.open(os.path.join(path, filename))\n",
        "\n",
        "    images.append(trans(img))"
      ],
      "metadata": {
        "id": "ztsWCr4rch1s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[]\n",
        "for tensor in testloader:\n",
        "  for label in tensor[1]:\n",
        "    labels.append(label.item())\n",
        "labels=labels[0:2000]"
      ],
      "metadata": {
        "id": "JjaUPREL59II"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "# Create the test loader\n",
        "batch_size=256\n",
        "currtestset = torch.utils.data.TensorDataset(torch.stack(images), torch.tensor(labels))\n",
        "currtestloader = torch.utils.data.DataLoader(currtestset, batch_size=2*batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "V2rsNZi3PhLs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now testing the corrupted images with our ResNET50_BN (Batch Normalization) model."
      ],
      "metadata": {
        "id": "fcKr-EpOmHdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(currtestloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS5SHs_Cm3pA",
        "outputId": "c922b9b2-3ba1-48c1-f3cf-79e73009fbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 4 test accuracy 36.45%: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 36.45 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(currtestset, 'testset.pt')\n",
        "# Load the test dataset\n",
        "# testset = torch.load('testset.pt')"
      ],
      "metadata": {
        "id": "g5SGJSmQ8XOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change ResNet50 BAtch norm layers to group norm"
      ],
      "metadata": {
        "id": "eEM2zn3Fnsni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below function changes BN layers to GN layers in ResNet50"
      ],
      "metadata": {
        "id": "dxwiy654sIlm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bn_model_to_gn(module, num_groups=32):\n",
        "    \"\"\"\n",
        "    Recursively traverse module and its children to replace all instances of `torch.nn.modules.batchnorm._BatchNorm` with `torch.nn.GroupNorm`.\n",
        "    Args:\n",
        "        module: your network module\n",
        "        num_groups: num_groups of GN\n",
        "    \"\"\"\n",
        "    mod = module\n",
        "    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n",
        "        mod = nn.GroupNorm(num_groups, module.num_features, eps=module.eps, affine=module.affine)\n",
        "        if module.affine:\n",
        "            mod.weight.data = module.weight.data.clone().detach()\n",
        "            mod.bias.data = module.bias.data.clone().detach()\n",
        "    for name, child in module.named_children():\n",
        "        mod.add_module(name, convert_bn_model_to_gn(child, num_groups=num_groups))\n",
        "    del module\n",
        "    return mod\n",
        "# Load the pre-trained ResNet50 model\n"
      ],
      "metadata": {
        "id": "pMspB058G9gl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_bn = models.resnet50(pretrained=True)\n",
        "resnet50_gn=convert_bn_model_to_gn(module, num_groups=32)"
      ],
      "metadata": {
        "id": "0TKRWsCjn2DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using previously trained the model,so just loading it to test the performance\n",
        "resnet50_gn=torch.load('/content/drive/MyDrive/CV_final_project_files/resnet50_gn.pt')"
      ],
      "metadata": {
        "id": "us12TXJZoHj2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = resnet50_gn.to(device)"
      ],
      "metadata": {
        "id": "tyQLybNOpM1M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can train the model by using this code, in case not using the previously trained model\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(trainloader)\n",
        "    i = 0\n",
        "    for data in pbar:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        pbar.set_description(\"Processing epoch {:d} minibatch {:d} train loss {:.3f}\".format(epoch,\\\n",
        "                                                            i+1, running_loss/(i+1)))\n",
        "        i += 1\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "zsm79Gjco1ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the ResNet50_GN with Normal Images"
      ],
      "metadata": {
        "id": "oIi8x1m3qiUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "resnet50.eval()\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(testloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = resnet50(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BArTvlIDou2j",
        "outputId": "8a1b0320-514c-4f10-b90b-79b205f92bc6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 20 test accuracy 45.19%: 100%|██████████| 20/20 [00:46<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 45.19 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the ResNet50_GN (Group Normalisation ) with corrupted images"
      ],
      "metadata": {
        "id": "yUL4bzWeqXlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    pbar = tqdm(currtestloader)\n",
        "    for data in pbar:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = resnet50(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pbar.set_description(\"minibatch {:d} test accuracy {:4.2f}%\".format(i+1,\\\n",
        "                                                            100.0*correct/total))\n",
        "        i += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %4.2f %%' % (100.0 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwbKErvjo6ij",
        "outputId": "52bd0031-f2bf-4dbf-df83-9d312311897a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "minibatch 4 test accuracy 36.45%: 100%|██████████| 4/4 [00:08<00:00,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 36.45 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OzR7R6g5rKpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------------------------Finished-------------------------------------------------"
      ],
      "metadata": {
        "id": "9ft7RsXbrOfp"
      }
    }
  ]
}